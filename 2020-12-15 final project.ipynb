{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful links:\n",
    "* https://www.youtube.com/watch?v=THduWAnG97k \n",
    "* https://spacy.io/usage/spacy-101"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Claim Text I Made Up:\n",
    "***\n",
    "**A vehicle** containing:\n",
    "**a first passenger** and **a second passenger**,\n",
    "where <font color='red'>the passenger</font>  jumps out <font color='blue'>the window</font> of <font color='green'>the vehicle</font>.\n",
    "***\n",
    "* **bold** are words that may have another words that rely on it for antecedent basis\n",
    "* <font color='red'>red</font> are words that have incorrect 112 2nd antecedent basis and should have a 112 2nd rejection\n",
    "* <font color='blue'>blue</font> are words that have incorrect 112 2nd antecedent basis and should be objected to\n",
    "* <font color='green'>green</font> are words that have correct 112 2nd antecedent basis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Claim Text for an Automobile:<br>\n",
    "from: https://www.nolo.com/legal-encyclopedia/sample-patent-claims-common-inventions.html\n",
    "\n",
    "***\n",
    "**A  vehicle**, comprising:\n",
    "**a body carriage** having **rotatable wheels** mounted thereunder for enabling <font color='green'> said body carriage </font> to roll along **a surface**\n",
    "**an engine** mounted in <font color='green'>said carriage</font> for producing rotational energy, and\n",
    "means for controllably coupling rotational energy from <font color='green'> said engine </font> to at least one of <font color='green'> said wheels </font> ,\n",
    "whereby <font color='green'> said carriage</font> can be propelled along <font color='green'> said surface</font>.\n",
    "***\n",
    "* **bold** are words that may have another words that rely on it for antecedent basis\n",
    "* <font color='red'>red</font> are words that have incorrect 112 2nd antecedent basis and should have a 112 2nd rejection\n",
    "* <font color='blue'>blue</font> are words that have incorrect 112 2nd antecedent basis and should be objected to\n",
    "* <font color='green'>green</font> are words that have correct 112 2nd antecedent basis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Claim for the Process of Sewing:<br>\n",
    "from: https://www.nolo.com/legal-encyclopedia/sample-patent-claims-common-inventions.html\n",
    "\n",
    "***\n",
    "**A method** for joining **a cloth** together, comprising the steps of:\n",
    "providing  <font color='green'> said cloth </font> and positioning **the cloth** together so that **an edge portion of one piece** overlaps **an adjacent edge portion** of <font color='green'> the other piece </font>, and\n",
    "passing **a thread** repeatedly through and along <font color='green'>the overlapping portions </font> in sequentially opposite directions and through sequentially spaced holes in <font color='green'>said overlapping adjacent portions </font>,\n",
    "whereby <font color='red'>said two pieces of cloth</font> will be attached along <font color='green'>said edge portions</font>.\n",
    "***\n",
    "* **bold** are words that may have another words that rely on it for antecedent basis\n",
    "* <font color='red'>red</font> are words that have incorrect 112 2nd antecedent basis and should have a 112 2nd rejection\n",
    "* <font color='blue'>blue</font> are words that have incorrect 112 2nd antecedent basis and should be objected to\n",
    "* <font color='green'>green</font> are words that have correct 112 2nd antecedent basis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Claim for a Pencil:<br>\n",
    "from: https://www.nolo.com/legal-encyclopedia/sample-patent-claims-common-inventions.html\n",
    "\n",
    "***\n",
    "**A hand-held writing instrument** comprising:\n",
    "**an elongated core-element means** that will leave **a marking line** if moved \n",
    "across **a paper or other similar surface**, and\n",
    "**an elongated holder** surrounding and encasing said <font color='green'> elongated core element means</font>, one portion of <font color='green'> said holder </font> being removable from **an end** thereof to expose **an end** of <font color='green'>said core-element means </font> so as to enable <font color='red'> said core-element means </font>to be exposed for writing,\n",
    "whereby <font color='red'>said holder </font> protects <font color='red'> said core element means</font> from breakage and provides **an enlarged means** for holding <font color='red'>  said core-element means </font> conveniently.\n",
    "***\n",
    "* **bold** are words that may have another words that rely on it for antecedent basis\n",
    "* <font color='red'>red</font> are words that have incorrect 112 2nd antecedent basis and should have a 112 2nd rejection\n",
    "* <font color='blue'>blue</font> are words that have incorrect 112 2nd antecedent basis and should be objected to\n",
    "* <font color='green'>green</font> are words that have correct 112 2nd antecedent basis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Claim for Concrete:<br>\n",
    "from: https://www.nolo.com/legal-encyclopedia/sample-patent-claims-common-inventions.html\n",
    "\n",
    "***\n",
    "**A rigid building and paving material** comprising **a mixture of: a sand and stones**, and **a hardened cement binder filling** <font color='blue'> the interstices</font> between and adhering to <font color='green'>the sand and stones</font>, whereby **a hardened, rigid, and strong matrix** for building and paving will be provided.\n",
    "***\n",
    "* **bold** are words that may have another words that rely on it for antecedent basis\n",
    "* <font color='red'>red</font> are words that have incorrect 112 2nd antecedent basis and should have a 112 2nd rejection\n",
    "* <font color='blue'>blue</font> are words that have incorrect 112 2nd antecedent basis and should be objected to\n",
    "* <font color='green'>green</font> are words that have correct 112 2nd antecedent basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://spacy.io/usage/spacy-101\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "\n",
    "# import the matcher\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "# load a model and create teh nlp objet\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please input your claim.\n",
      "A vehicle containing: a first passenger and a second passenger, where the passenger jumps out the window of the vehicle.\n",
      "\n",
      " a first passenger <-> the passenger -- Possible 112 2nd issue!\n",
      "\n",
      " a second passenger <-> the passenger -- Possible 112 2nd issue!\n",
      "\n",
      "? <-> the window -- claim objection -- 'the/said' should be 'a/an'\n"
     ]
    }
   ],
   "source": [
    "text = input(\"Please input your claim.\\n\")\n",
    "\n",
    "text = text.lower()\n",
    "\n",
    "# process some text\n",
    "doc = nlp(text)\n",
    "\n",
    "# for token in doc:\n",
    "#     print(f\"{token.text:{10}} {token.pos_:{10}} {token.tag_:{10}}\")\n",
    "\n",
    "################################# Matching Patterns #########################################    \n",
    "\n",
    "# intialize the matcher with the shared vocab \n",
    "matcher_a = Matcher(nlp.vocab)\n",
    "matcher_b = Matcher(nlp.vocab)\n",
    "\n",
    "# add patterns to matcher_a\n",
    "pattern = [{\"TEXT\": \"a\"}, # pattern starts with 'a'\n",
    "           {\"POS\":\"ADJ\", \"OP\":\"*\"}, # 0 or more  adjectives\n",
    "           {\"POS\":\"NOUN\"}] # pattern ends with a noun\n",
    "matcher_a.add(\"A_ADJ_PATTERN\", None, pattern)\n",
    "\n",
    "pattern = [{\"TEXT\": \"an\"}, # pattern starts with 'an'\n",
    "           {\"POS\":\"ADJ\", \"OP\":\"*\"}, # 0 or more  adjectives\n",
    "           {\"POS\":\"NOUN\"}] # pattern ends with a noun\n",
    "matcher_a.add(\"AN_ADJ_PATTERN\", None, pattern)\n",
    "\n",
    "# run matcher_a on our claims\n",
    "matches_a = matcher_a(doc)\n",
    "\n",
    "# iterate over the matches found with matcher_a to print the match from the doc \n",
    "for match_id, start, end in matches_a: \n",
    "    matched_span = doc[start:end] # get the matched span\n",
    "#     print(matched_span.text)\n",
    "\n",
    "# add patterns to matcher_b\n",
    "pattern =[{\"TEXT\": \"the\"},# pattern starts with 'the'\n",
    "          {\"POS\":\"ADJ\", \"OP\":\"*\"}, # 0 or more  adjectives\n",
    "          {\"POS\":\"NOUN\"}]# pattern ends with a noun\n",
    "matcher_b.add(\"THE_ADJ_PATTERN\", None, pattern) # \n",
    "\n",
    "pattern =[{\"TEXT\": \"said\"}, # pattern starts with 'the'\n",
    "          {\"POS\":\"ADJ\", \"OP\":\"*\"},  # 0 or more  adjectives\n",
    "          {\"POS\":\"NOUN\"}]# pattern ends with a noun\n",
    "matcher_b.add(\"SAID_ADJ_PATTERN\", None, pattern)\n",
    "\n",
    "# run matcher_b on our claims\n",
    "matches_b = matcher_b(doc)\n",
    "\n",
    "# iterate over the matches found with matcher_b to print the match from the doc \n",
    "for match_id, start, end in matches_b:\n",
    "#     get the matched span\n",
    "    matched_span = doc[start:end]\n",
    "    \n",
    "################################# Filter Noun Chunks #########################################      \n",
    "\n",
    "filter_noun_chunks_a = []\n",
    "filter_noun_chunks_b = []\n",
    "filter_noun_chunks_a_roots = []\n",
    "filter_noun_chunks_b_roots = []\n",
    " \n",
    "\n",
    "def filter_noun_chunk(noun_chunks):\n",
    "    for i in noun_chunks:\n",
    "        if (\"a \" in i.text) or (\"an \" in i.text):\n",
    "            filter_noun_chunks_a.append(i)\n",
    "            filter_noun_chunks_a_roots.append(i.root.text)\n",
    "#             print(i)\n",
    "        elif (\"the \" in i.text) or (\"said \" in i.text):\n",
    "            filter_noun_chunks_b.append(i)\n",
    "            filter_noun_chunks_b_roots.append(i.root.text)\n",
    "#             print(i)\n",
    "#     print(filter_noun_chunks_a)\n",
    "#     print(filter_noun_chunks_b)\n",
    "    return(filter_noun_chunks_a_roots, filter_noun_chunks_b_roots)  \n",
    "#     print(\"-- a or an --\")\n",
    "#     print(\"-- the or said --\")\n",
    "\n",
    "################################# Find and Print 112 2nd issues #########################################     \n",
    "\n",
    "for match_a, start_a, end_a in matches_a:\n",
    "    for match_b, start_b, end_b in matches_b:\n",
    "#         print(\"end match a: \", end_a)\n",
    "#         print(\"start match b: \", start_b)\n",
    "#         if end_a < start_b:\n",
    "        match_a_span = doc[start_a:end_a]\n",
    "        match_a_noun = doc[end_a-1]\n",
    "        match_b_span = doc[start_b:end_b]\n",
    "        match_b_noun = doc[end_b-1]\n",
    "        match_a_other = doc[start_a+1:end_a-1]\n",
    "        match_b_other = doc[start_b+1:end_b-1]\n",
    "        if match_a_noun.text == match_b_noun.text:\n",
    "            if match_a_other.text == match_b_other.text:\n",
    "                pass  #print(match_a_span.text, \"<->\", match_b_span.text, \"-- All good!\") \n",
    "            else:\n",
    "                print(\"\\n\",match_a_span.text, \"<->\", match_b_span.text, \"-- Possible 112 2nd issue!\")\n",
    "                \n",
    "################################# Find and Print Claim Objections #########################################         \n",
    "\n",
    "noun_chunks = list(doc.noun_chunks)\n",
    "# print(noun_chunks)\n",
    "\n",
    "filter_noun_chunk(noun_chunks)\n",
    "\n",
    "for match_b, start_b, end_b in matches_b:\n",
    "    match_b_noun = doc[end_b-1]\n",
    "    match_b_span = doc[start_b:end_b]\n",
    "#     print(\"match_b_noun:\", match_b_noun)\n",
    "#     print(\"roots:\", filter_noun_chunks_a_roots)\n",
    "    if match_b_noun.text not in filter_noun_chunks_a_roots:\n",
    "         print(\"\\n? <->\", match_b_span.text, \"-- claim objection -- 'the/said' should be 'a/an'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
